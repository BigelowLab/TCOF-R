[
  {
    "objectID": "files-many.html",
    "href": "files-many.html",
    "title": "Many files",
    "section": "",
    "text": "It can be a challenge to face many files to work with. Often they are scattered across a number of directories, and it can be tempting for a novice to manually read each one in a script, and then try to bind them together. Even worse, sometimes files can less than cooperative for new coders by having complicated or non-standard layouts.\nAnd, of course, invariably we want do handle the contents of the many files as one object, rather than many objects with one object per file.\nIn this tutorial we walk through some of the techniques available to the coder to simplify the steps to importing multi-file datasets into R (or python!)",
    "crumbs": [
      "E pluribus unum"
    ]
  },
  {
    "objectID": "files-many.html#mocked-data",
    "href": "files-many.html#mocked-data",
    "title": "Many files",
    "section": "Mocked data",
    "text": "Mocked data\nWe have prepared a mock up of a dataset; it consists of studies of guppies from 5 sites. At each site we generate two files: a “gup” data file and a “YAML” metadata file. Each is a text file, but the .gup file consists of two parts: a header followed by the a CSV style table of data.",
    "crumbs": [
      "E pluribus unum"
    ]
  },
  {
    "objectID": "files-many.html#finding-files",
    "href": "files-many.html#finding-files",
    "title": "Many files",
    "section": "Finding files",
    "text": "Finding files\nR-language provides convenient tools for locating files. If you find these don’t suit your needs, then consider using the fs R package which has more features. For this project, we’ll stick to using base R functionality as much as possible.\nHere we use the list_guppy() function. Here’s what it finds…\n\nsource(\"setup.R\")\n\nhere() starts at /Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R\n\ngup_files = list_guppy() |&gt;\n  print()\n\n[1] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_01/site_01.gup\"\n[2] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_02/site_02.gup\"\n[3] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_03/site_03.gup\"\n[4] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_04/site_04.gup\"\n[5] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_05/site_05.gup\"\n\n\nLet’s take a closer look at the function. The built-in list.files() function is the workhorse here.\n\nlist_guppy = function(path = here::here(\"data\", \"guppy\"),\n                      pattern = glob2rx(\"*.gup\"),\n                      recursive = TRUE){\n  list.files(path, pattern = pattern, recursive= TRUE, full.names = TRUE)\n}\n\nThe function accepts three arguments:\n\npath this is a string providing the pathway to the data files\npattern this is regular expression. We converted a “glob” (wildcard notation) to a “regex” (regular expression) using the handy glob2rx() function where we requested the pattern of “any characters followed by ‘.R’ at the very end”.\nrecursive tells list.files() to search deeply into subdirectories of path.\nfull.names results in fully-formed filenames including the path.\n\n\nReading the files",
    "crumbs": [
      "E pluribus unum"
    ]
  },
  {
    "objectID": "files-configurations.html",
    "href": "files-configurations.html",
    "title": "Configuration files",
    "section": "",
    "text": "Many times we have a set of values used by a workflow that aren’t exactly data, but are values for parameters and arguments. These are typically stored in a configuration file which can come in a variety of standard formats. A common format is YAML which is a name-value pairing written in plain text, and it is easy work with in R.",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "files-configurations.html#an-example-configuration-file",
    "href": "files-configurations.html#an-example-configuration-file",
    "title": "Configuration files",
    "section": "An example configuration file",
    "text": "An example configuration file\nHere we have a small configuration file. It looks like this:\nsite_id: site_01\nresearcher: JPO\ntime: 2020-05-16T07:26:25 UTC\nshade: 30.0\ngps_codes:\n- c\n- q\n- q\nMost items have a simple name-value association such as shade = 30.0, while others have more complex associations like gps_codes = c(\"c\", \"q\", \"q\").",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "files-configurations.html#reading-a-configuration-file",
    "href": "files-configurations.html#reading-a-configuration-file",
    "title": "Configuration files",
    "section": "Reading a configuration file",
    "text": "Reading a configuration file\nThe yaml R package will read and write YAML files. In R the contents of the file become a named list.\n\ncfg = yaml::read_yaml(\"data/guppy/site_01/site_01.yaml\") \nstr(cfg)\n\nList of 5\n $ site_id   : chr \"site_01\"\n $ researcher: chr \"JPO\"\n $ time      : chr \"2020-05-16T07:26:25 UTC\"\n $ shade     : num 30\n $ gps_codes : chr [1:3] \"c\" \"q\" \"q\"\n\n\nNote that items have been read as charcater (string) or number. Other data types are possibke but these two are the most common.",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "files-configurations.html#modifying-a-configuration",
    "href": "files-configurations.html#modifying-a-configuration",
    "title": "Configuration files",
    "section": "Modifying a configuration",
    "text": "Modifying a configuration\nYou can update a value in the configuration. The following are all equivalent modifications.\n\ncfg$shade = 25.0\ncfg[[\"shade\"]] = 25.0\ncfg[[4]] = 25.0\n\nYou can add a name-value pairing.\n\ncfg$alphabet = letters[1:5]\nstr(cfg)\n\nList of 6\n $ site_id   : chr \"site_01\"\n $ researcher: chr \"JPO\"\n $ time      : chr \"2020-05-16T07:26:25 UTC\"\n $ shade     : num 25\n $ gps_codes : chr [1:3] \"c\" \"q\" \"q\"\n $ alphabet  : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n\n\nAnd then you can remove an element.\n\ncfg$time = NULL\nstr(cfg)\n\nList of 5\n $ site_id   : chr \"site_01\"\n $ researcher: chr \"JPO\"\n $ shade     : num 25\n $ gps_codes : chr [1:3] \"c\" \"q\" \"q\"\n $ alphabet  : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "files-configurations.html#writing-a-configuration-file",
    "href": "files-configurations.html#writing-a-configuration-file",
    "title": "Configuration files",
    "section": "Writing a configuration file",
    "text": "Writing a configuration file\nTo write the configuration we can use the yaml R package again.\n\nyaml::write_yaml(cfg, \"~/my_test_config.yaml\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe easiest way to get a configuration going is to start a named list in R for your important items, and then save that to a YAML file. You can edit it as a text file to modify, add or remove elements.",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Tandy Center for Ocean Forecasting\nHere you’ll find short tutorials on methods for transforming your coding by leveraging basic tools for capturing, organizing, accessing and analyzing your data. Use the side bar at left to navigate among various topics (some of which overlap.)\n\nFiles with bad headers Have a file that has a complicated header with information you want to extract along with the data?\nE pluribus unum Have many tabular files you want to bind together as one big table?",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "files-header-table.html",
    "href": "files-header-table.html",
    "title": "Tricky files",
    "section": "",
    "text": "Some files are easy to read like CSV or Excel or TEXT files. They provide clean tabular data, often with meaningful column names, and we can generally rely upon existing software to read them for us.\nBut not all files. Sometimes you will encounter files that look easy to read but have a funny hitch like a header section before the table, or a header section followed by binary table (we are looking at you, flow cytometrists!)\nHere we have a file that is simply a small header section followed by a plain old CSV table with 18 records. Here are the first few lines followed by the last 2.\n## Guppy studies\nSITE: site_01\nCOORDS (x y crs): 452032.1 4857765.1 EPSG:26919\nTIME: 2020-05-16T07:26:25 UTC\n## data\nid,treatment,count,dose\n1,C,32,0.7\n2,B,71,0.5\n3,D,54,0.6\n4,C,57,0.7\n    .\n    .\n    .\n17,D,37,0.5\n18,E,60,0.8\nNow whe have table readers galore to chose among including read.csv and reader::read_csv. Each includes a skip argument to skip over the header which we can use to read the table alone.\n\nRead the table\n\nsource(\"setup.R\")\n\nhere() starts at /Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R\n\nx = readr::read_csv(\"data/guppy/site_01/site_01.gup\",\n                    show_col_types = FALSE,\n                    skip = 5,\n                    col_names = TRUE) |&gt;\n  dplyr::glimpse()\n\nRows: 18\nColumns: 4\n$ id        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18\n$ treatment &lt;chr&gt; \"C\", \"B\", \"D\", \"C\", \"C\", \"A\", \"B\", \"B\", \"A\", \"B\", \"B\", \"A\", …\n$ count     &lt;dbl&gt; 32, 71, 54, 57, 32, 55, 66, 61, 60, 33, 67, 34, 42, 60, 49, …\n$ dose      &lt;dbl&gt; 0.7, 0.5, 0.6, 0.7, 1.0, 0.4, 0.0, 0.0, 0.6, 0.4, 0.0, 0.9, …\n\n\nSo that’s pretty easy, but what happens if it is important to attach some of the header info to the table we read? How do we read that and attach it as a attribute to the table?\n\n\nRead the header\nWe could follow a different path by reading the first 4 lines as a character (string) vector and parsing what we need for the text. Then we could use the above to read the remainder of the file as a table.\n\nss = readLines(\"data/guppy/site_01/site_01.gup\", n = 4) |&gt;\n  stringr::str_split(stringr::fixed(\": \"), n = 2)\nss = ss[-1]    # we don't need the first line\nss\n\n[[1]]\n[1] \"SITE\"    \"site_01\"\n\n[[2]]\n[1] \"COORDS (x y crs)\"              \"452032.1 4857765.1 EPSG:26919\"\n\n[[3]]\n[1] \"TIME\"                    \"2020-05-16T07:26:25 UTC\"\n\n\nstr_split() always produces a list with one element for each line of text.\n\n\nParse the header\nNow we have a list with one element per line of text, where each element has 2 elements itself: the string before “:” and the string after “:” . Extracting the site is easy,\n\nsite = ss[[1]][2]  # the second element of the first element\nsite\n\n[1] \"site_01\"\n\n\nand the time should be a straight forward conversion to a date-time class.\n\ntime = ss[[3]][2] |&gt;  # the second element of the third element\n  as.POSIXct(format = \"%Y-%m-%dT%H:%M:%S UTC\", tz = \"UTC\")\ntime\n\n[1] \"2020-05-16 07:26:25 UTC\"\n\n\nBut what of the second line? It has three bits of info: two numerics (x and y) and one string (crs). Well, first let’s extract them.\n\n                         # the second element of the second element\nxyc = stringr::str_split(ss[[2]][2], stringr::fixed(\" \"), n = 3)\nxyc\n\n[[1]]\n[1] \"452032.1\"   \"4857765.1\"  \"EPSG:26919\"\n\n\nKeep in mind the str_split() returns a list with one element per line of input. So this should be easy to make a list we can subsequently attach to the table as an attribute.\n\nxcoord = xyc[[1]][1] |&gt; as.numeric()  # first element of first element\nycoord = xyc[[1]][2] |&gt; as.numeric()  # second element of first element\ncrs = xyc[[1]][3]                     # third element of first element\n\n\n\nAdd as an attribute\nYou can have anything as an attribute to an object using the attr() function. Attributes are small bits of metadata associated with the object to which it is attached. Whether it is a good idea add an attribute is often worth debating especially if the attribute is large or you need ready access to it. But in the case it is a small bit of info and may not be useful in an immediate sense. Below we attach a “metadata” attribute to our table, x.\n\nmy_atts = list(site_id = site,\n               time = time,\n               x = xcoord,\n               y = ycoord,\n               crs = crs)\n\nattr(x, \"metadata\") = my_atts\n\nYou can get all of the attributes (prepare yourself - it can be a lot!) using attributes(). Keep in mind that other steps may have added attributes to your table, too.\n\nattributes(x)\n\n$row.names\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18\n\n$names\n[1] \"id\"        \"treatment\" \"count\"     \"dose\"     \n\n$spec\ncols(\n  id = col_double(),\n  treatment = col_character(),\n  count = col_double(),\n  dose = col_double()\n)\n\n$problems\n&lt;pointer: 0x7f7fa164f540&gt;\n\n$class\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n$metadata\n$metadata$site_id\n[1] \"site_01\"\n\n$metadata$time\n[1] \"2020-05-16 07:26:25 UTC\"\n\n$metadata$x\n[1] 452032.1\n\n$metadata$y\n[1] 4857765\n\n$metadata$crs\n[1] \"EPSG:26919\"\n\n\nBut, there at the end, you can see your attributes in ‘metadata’. We can get those back if needed.\n\nmy_atts = attr(x, \"metadata\")\nmy_atts\n\n$site_id\n[1] \"site_01\"\n\n$time\n[1] \"2020-05-16 07:26:25 UTC\"\n\n$x\n[1] 452032.1\n\n$y\n[1] 4857765\n\n$crs\n[1] \"EPSG:26919\"\n\n\n\n\nIn another context\nIn the E pluribus unum tutorial we will read these files in a slightly different way, but we use the same approach - read the header as a block of text and then read the remainder as a table. What we do with the header info in that other context is different than here. In that other context we only add the crs as an attribute. site_id, time, x and y are not added as attributes, but instead are added as new variables (columns) in the table.\n\nx = x |&gt;\n  dplyr::mutate(\n    site_id = site,\n    time = time,\n    x = xcoord,\n    y = ycoord, \n    .before = 1) |&gt;\n  dplyr::glimpse()\n\nRows: 18\nColumns: 8\n$ site_id   &lt;chr&gt; \"site_01\", \"site_01\", \"site_01\", \"site_01\", \"site_01\", \"site…\n$ time      &lt;dttm&gt; 2020-05-16 07:26:25, 2020-05-16 07:26:25, 2020-05-16 07:26:…\n$ x         &lt;dbl&gt; 452032.1, 452032.1, 452032.1, 452032.1, 452032.1, 452032.1, …\n$ y         &lt;dbl&gt; 4857765, 4857765, 4857765, 4857765, 4857765, 4857765, 485776…\n$ id        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18\n$ treatment &lt;chr&gt; \"C\", \"B\", \"D\", \"C\", \"C\", \"A\", \"B\", \"B\", \"A\", \"B\", \"B\", \"A\", …\n$ count     &lt;dbl&gt; 32, 71, 54, 57, 32, 55, 66, 61, 60, 33, 67, 34, 42, 60, 49, …\n$ dose      &lt;dbl&gt; 0.7, 0.5, 0.6, 0.7, 1.0, 0.4, 0.0, 0.0, 0.6, 0.4, 0.0, 0.9, …\n\n\nIt’s just a different approach and may seem, at this time, like a silly waste of data space since every row has the same values for site_id, time, x and y. But in that other context it is a gold mine.",
    "crumbs": [
      "Files with bad headers"
    ]
  }
]