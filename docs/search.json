[
  {
    "objectID": "files-many.html",
    "href": "files-many.html",
    "title": "Many files",
    "section": "",
    "text": "It can be a challenge to face many files to work with. Often they are scattered across a number of directories, and it can be tempting for a novice to manually read each one in a script, and then try to bind them together. Even worse, sometimes files can less than cooperative for new coders by having complicated or non-standard layouts.\nAnd, of course, invariably we want do handle the contents of the many files as one object, rather than many objects with one object per file.\nIn this tutorial we walk through some of the techniques available to the coder to simplify the steps to importing multi-file datasets into R (or python!)",
    "crumbs": [
      "E pluribus unum"
    ]
  },
  {
    "objectID": "files-many.html#mocked-data",
    "href": "files-many.html#mocked-data",
    "title": "Many files",
    "section": "Mocked data",
    "text": "Mocked data\nWe have prepared a mock up of a dataset; it consists of studies of guppies from 5 sites. At each site we generate two files: a “gup” data file and a “YAML” configuration file. Each is a text file, but the .gup file consists of two parts: a header followed by the a CSV style table of data.",
    "crumbs": [
      "E pluribus unum"
    ]
  },
  {
    "objectID": "files-many.html#finding-files",
    "href": "files-many.html#finding-files",
    "title": "Many files",
    "section": "Finding files",
    "text": "Finding files\nR-language provides convenient tools for locating files. If you find these don’t suit your needs, then consider using the fs R package which has more features. For this project, we’ll stick to using base R functionality as much as possible.\nHere we use the list_guppy() function. Here’s what it finds…\n\nsource(\"setup.R\")\n\nhere() starts at /Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R\n\ngup_files = list_guppy() |&gt;\n  print()\n\n[1] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_01/site_01.gup\"\n[2] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_02/site_02.gup\"\n[3] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_03/site_03.gup\"\n[4] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_04/site_04.gup\"\n[5] \"/Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R/data/guppy/site_05/site_05.gup\"\n\n\n\nA closer look at thr function\nLet’s take a closer look at the function. The built-in list.files() function is the workhorse here.\n\nlist_guppy = function(path = here::here(\"data\", \"guppy\"),\n                      pattern = glob2rx(\"*.gup\"),\n                      recursive = TRUE){\n  list.files(path, pattern = pattern, recursive= TRUE, full.names = TRUE)\n}\n\nThe function accepts three arguments:\n\npath this is a string providing the pathway to the data files\npattern this is regular expression. We converted a “glob” (wildcard notation) to a “regex” (regular expression) using the handy glob2rx() function where we requested the pattern of “any characters followed by ‘.R’ at the very end”.\nrecursive tells list.files() to search deeply into subdirectories of path.\nfull.names results in fully-formed filenames including the path.",
    "crumbs": [
      "E pluribus unum"
    ]
  },
  {
    "objectID": "files-many.html#reading-the-files",
    "href": "files-many.html#reading-the-files",
    "title": "Many files",
    "section": "Reading the files",
    "text": "Reading the files\nWe have already written a convenience function, read_guppy(), which reads both the configuration file and the “gup” data file files, and then merges them into one file.\n\nBasic use\nWe pass in the listing of 5 filenames, and the function returns a single table\n\nx = read_guppy(gup_files) |&gt;\n  glimpse()\n\nRows: 105\nColumns: 11\n$ site_id    &lt;chr&gt; \"site_01\", \"site_01\", \"site_01\", \"site_01\", \"site_01\", \"sit…\n$ x          &lt;dbl&gt; 452032.1, 452032.1, 452032.1, 452032.1, 452032.1, 452032.1,…\n$ y          &lt;dbl&gt; 4857765, 4857765, 4857765, 4857765, 4857765, 4857765, 48577…\n$ time       &lt;dttm&gt; 2020-05-16 07:26:25, 2020-05-16 07:26:25, 2020-05-16 07:26…\n$ researcher &lt;chr&gt; \"JPO\", \"JPO\", \"JPO\", \"JPO\", \"JPO\", \"JPO\", \"JPO\", \"JPO\", \"JP…\n$ shade      &lt;dbl&gt; 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,…\n$ gps_codes  &lt;chr&gt; \"c-q-q\", \"c-q-q\", \"c-q-q\", \"c-q-q\", \"c-q-q\", \"c-q-q\", \"c-q-…\n$ id         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ treatment  &lt;chr&gt; \"C\", \"B\", \"D\", \"C\", \"C\", \"A\", \"B\", \"B\", \"A\", \"B\", \"B\", \"A\",…\n$ count      &lt;dbl&gt; 32, 71, 54, 57, 32, 55, 66, 61, 60, 33, 67, 34, 42, 60, 49,…\n$ dose       &lt;dbl&gt; 0.7, 0.5, 0.6, 0.7, 1.0, 0.4, 0.0, 0.0, 0.6, 0.4, 0.0, 0.9,…\n\n\nLet’s double check that the number of sites matches the number of files.\n\ndplyr::count(x, site_id)\n\n# A tibble: 5 × 2\n  site_id     n\n  &lt;chr&gt;   &lt;int&gt;\n1 site_01    18\n2 site_02    23\n3 site_03    29\n4 site_04    10\n5 site_05    25\n\n\nWe can also read the same data in, but this time request a spatial sf objects, where each row’s x and y coordinates are transformed into spatial POINT.\n\nx = read_guppy(gup_files, form = \"sf\") |&gt;\n  print()\n\nSimple feature collection with 105 features and 9 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 452032.1 ymin: 4857756 xmax: 452066.9 ymax: 4857774\nProjected CRS: NAD83 / UTM zone 19N\n# A tibble: 105 × 10\n   site_id time                researcher shade gps_codes    id treatment count\n * &lt;chr&gt;   &lt;dttm&gt;              &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         1 C            32\n 2 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         2 B            71\n 3 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         3 D            54\n 4 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         4 C            57\n 5 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         5 C            32\n 6 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         6 A            55\n 7 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         7 B            66\n 8 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         8 B            61\n 9 site_01 2020-05-16 07:26:25 JPO           30 c-q-q         9 A            60\n10 site_01 2020-05-16 07:26:25 JPO           30 c-q-q        10 B            33\n# ℹ 95 more rows\n# ℹ 2 more variables: dose &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhether you request a tibble (aka table or data.frame) or an sf object, you can use all of the tidyverse tools for subsequent analyses. If you do your work with spatial analyses in mind, then sf is the way to go.\n\n\n\n\nA closer look\nBut how does the function work? How does it merge the metadata file with the tabular data?\nThe process is the same if you provide one filename or many filenames. We have written the read_guppy() function with the comments you see below in the pseudo-code, where each commetn is flagged with a double hash ##. You can study the code alongside the comments to follow along.\nfor each filename\n  check that the file at filename exists\n  use string processing to \"make\" the companion medatdata filename\n  read the metadata\n    check that the metadata file exists\n    read the metadata as a YAML file\n    return the metadata\n  scan all of the text lines in the filename\n    parse the header extracting the bits of info we want\n    read the table directly from the text\n    mutate the the table to include columns of data from the metadata and the header\n  add the crs info as an attribute\n  return the table\n  \nbind all of the tables by row\n\nconvert to sf-object if the user so requests\n\nreturn the table/sf-object\n\n\n\n\n\n\nTip\n\n\n\nReading and binding tables is such a common task it is well worth learning how to write your own functions rather than waiting for a solution to appear online. Once you have done one or two of these it gets to be very easy to do more as you combine little bites into a whole sandwich.",
    "crumbs": [
      "E pluribus unum"
    ]
  },
  {
    "objectID": "files-configurations.html",
    "href": "files-configurations.html",
    "title": "Configuration files",
    "section": "",
    "text": "Many times we have a set of values used by a workflow that aren’t exactly data, but are values for parameters and arguments. These are typically stored in a configuration file which can come in a variety of standard formats. A common format is YAML which is a name-value pairing written in plain text, and it is easy work with in R.",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "files-configurations.html#an-example-configuration-file",
    "href": "files-configurations.html#an-example-configuration-file",
    "title": "Configuration files",
    "section": "An example configuration file",
    "text": "An example configuration file\nHere we have a small configuration file. It looks like this:\nsite_id: site_01\nresearcher: JPO\ntime: 2020-05-16T07:26:25 UTC\nshade: 30.0\ngps_codes:\n- c\n- q\n- q\nMost items have a simple name-value association such as shade = 30.0, while others have more complex associations like gps_codes = c(\"c\", \"q\", \"q\").",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "files-configurations.html#reading-a-configuration-file",
    "href": "files-configurations.html#reading-a-configuration-file",
    "title": "Configuration files",
    "section": "Reading a configuration file",
    "text": "Reading a configuration file\nThe yaml R package will read and write YAML files. In R the contents of the file become a named list.\n\ncfg = yaml::read_yaml(\"data/guppy/site_01/site_01.yaml\") \nstr(cfg)\n\nList of 5\n $ site_id   : chr \"site_01\"\n $ researcher: chr \"JPO\"\n $ time      : chr \"2020-05-16T07:26:25 UTC\"\n $ shade     : num 30\n $ gps_codes : chr [1:3] \"c\" \"q\" \"q\"\n\n\nNote that items have been read as charcater (string) or number. Other data types are possibke but these two are the most common.",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "files-configurations.html#modifying-a-configuration",
    "href": "files-configurations.html#modifying-a-configuration",
    "title": "Configuration files",
    "section": "Modifying a configuration",
    "text": "Modifying a configuration\nYou can update a value in the configuration. The following are all equivalent modifications.\n\ncfg$shade = 25.0\ncfg[[\"shade\"]] = 25.0\ncfg[[4]] = 25.0\n\nYou can add a name-value pairing.\n\ncfg$alphabet = letters[1:5]\nstr(cfg)\n\nList of 6\n $ site_id   : chr \"site_01\"\n $ researcher: chr \"JPO\"\n $ time      : chr \"2020-05-16T07:26:25 UTC\"\n $ shade     : num 25\n $ gps_codes : chr [1:3] \"c\" \"q\" \"q\"\n $ alphabet  : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n\n\nAnd then you can remove an element.\n\ncfg$time = NULL\nstr(cfg)\n\nList of 5\n $ site_id   : chr \"site_01\"\n $ researcher: chr \"JPO\"\n $ shade     : num 25\n $ gps_codes : chr [1:3] \"c\" \"q\" \"q\"\n $ alphabet  : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "files-configurations.html#writing-a-configuration-file",
    "href": "files-configurations.html#writing-a-configuration-file",
    "title": "Configuration files",
    "section": "Writing a configuration file",
    "text": "Writing a configuration file\nTo write the configuration we can use the yaml R package again.\n\nyaml::write_yaml(cfg, \"~/my_test_config.yaml\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe easiest way to get a configuration going is to start a named list in R for your important items, and then save that to a YAML file. You can edit it as a text file to modify, add or remove elements.",
    "crumbs": [
      "Configuration files"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Tandy Center for Ocean Forecasting\nHere you’ll find short tutorials on methods for transforming your coding by leveraging basic tools for capturing, organizing, accessing and analyzing your data. Use the side bar at left to navigate among various topics (some of which overlap.)\n\nIterations When you really want to repeat yourself repetitiously over and over.\nConfiguration files Sometimes you need to store metadata in a file - try YAML!\nFiles with bad headers Have a file that has a complicated header with information you want to extract along with the data?\nE pluribus unum Have many tabular files you want to bind together as one big table?",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "iterations.html",
    "href": "iterations.html",
    "title": "Iterations",
    "section": "",
    "text": "Iteration - just what the heck is it really? The word comes from the Latin ‘iterare’ which means to repeat. Computer programs are perfect for doing repetitious things which releases the coder from mundane tasks so we can spend more time checking the internet. But they do have an initial cost - somebody has to code up the iteration. That’s what this tutorial is about: how to code up iterations.\nThe most famous iteration framework is the for-loop, but it has cousins in the repeat-until and while-do constructs. R-language has additional tools built in for iterating. These are in the apply family including lappy, sapply, mapply, tapply and vapply. Third party packages, such as those from Tidyverse and data.table also provide tools for iteration.",
    "crumbs": [
      "Iterations"
    ]
  },
  {
    "objectID": "iterations.html#the-for-loop",
    "href": "iterations.html#the-for-loop",
    "title": "Iterations",
    "section": "The for-loop",
    "text": "The for-loop\nThe for-loop has a very simple design…\nfor (each of these-things){\n  do this\n}\nTechnically, we don’t need to add the curly-braced code block, it could be simply…\nfor (each of these-things) do this\n… but it is always better to err on the side of readability - a code block is simply easier to read than a one-liner.\n\nSome example data\nLet’s make a simple named vector to work with.\n\nx = c(A = \"Alan\", B = \"Beryl\", C = \"Carlos\")\n\n\n\nHow to iterate over these-things\nWhat goes into the (each of these-things)? You have three choices here: a positional index (1,2,3), a name (A, B, C) or the items themselves (Alan, Beryl, Carlos). Each time the loop runs, it selects one item from your these-things and “delivers” it into the code block.\n\nIterate by position\nHere’s an example using positional indices. Note that we chose to use seq_along(x) to generate our sequence: 1, 2, 3. Using seq_along(x) and seq_len(length(x)) are considered good practice because they will not throw an error if you happen to have an x with no elements (it happens!) and instead will skip the loop. In our case, we generate our sequence with seq_along(x) which produces 1, 2, 3.\n\nfor (i in seq_along(x)){\n  cat(\"Hello,\", x[i], \"you are number\", i, \"\\n\")\n}\n\nHello, Alan you are number 1 \nHello, Beryl you are number 2 \nHello, Carlos you are number 3 \n\n\nUsing positional indices is often very useful, but keep in mind you can control the order of the sequence if you like. Note here how we reverse the order.\n\nfor (i in rev(seq_along(x))){\n  cat(\"Hello,\", x[i], \"you are number\", i, \"\\n\")\n}\n\nHello, Carlos you are number 3 \nHello, Beryl you are number 2 \nHello, Alan you are number 1 \n\n\n\n\nIterate by name\nOf course our object with three elements is a named vector. So we could use the names to iterate.\n\nfor (letter in names(x)){\n  cat(\"Your name is\", x[[letter]], \"and your letter is\", letter, \"\\n\")\n}\n\nYour name is Alan and your letter is A \nYour name is Beryl and your letter is B \nYour name is Carlos and your letter is C \n\n\nHere, too, you may arrange the order as you please.\n\nfor (letter in c(\"B\", \"A\", \"C\")){\n  cat(\"Your name is\", x[[letter]], \"and your letter is\", letter, \"\\n\")\n}\n\nYour name is Beryl and your letter is B \nYour name is Alan and your letter is A \nYour name is Carlos and your letter is C \n\n\n\n\n\n\n\n\nWarning\n\n\n\nIs your vector or list unnamed? What do you think will happen if you try to iterate by name? Will it throw an error? Skip the loop? Burst into flames and delete your hard drive?\n\n\n\n\nIterate by item\nFinally, we can iterate by item instead of by position or name.\n\nfor (this_person in x){\n  cat(\"Hi there,\", this_person, \"I don't know your letter or position\\n\")\n}\n\nHi there, Alan I don't know your letter or position\nHi there, Beryl I don't know your letter or position\nHi there, Carlos I don't know your letter or position\n\n\nNote that iterating by item means we lose the context of order - we don’t know in the code block anything about where in x we come from, and often it doesn’t matter.",
    "crumbs": [
      "Iterations"
    ]
  },
  {
    "objectID": "iterations.html#iteration-with-lapply-and-sapply",
    "href": "iterations.html#iteration-with-lapply-and-sapply",
    "title": "Iterations",
    "section": "Iteration with lapply and sapply",
    "text": "Iteration with lapply and sapply\nlapply and sapply are very similar functions. Each accepts a multi-element object over which it iterates. At each iteration it applies a function of your choosing to the current element. This function you choose mustr accept one argument. Once again, we can iterate over positional indices, names (if any) or over the items themselves.\nUnlike for-loops, the *apply (where * is “l”, “s”, etc) functions actually return something to you, which opens up all sorts of programming possibilities. Here’s a bit of pseudo-code using a generic *apply. The value of result will hold one modified_thing for every element of these_things.\nresult = *apply(these_things,\n                function(this_thing){\n                  modified_thing = do_something(this_thing)\n                  return(modified_thing))\n                })\n\nlapply()\nLet’s try it by iterating over names in our example data.\n\nresult = lapply(names(x),\n                function(name){\n                  r = paste(\"Your name is\", x[[name]], \"and your name has\", \n                            nchar(x[[name]]), \"characters\", sep = \" \")\n                  return(r)\n                })\n\nSo what is in result?\n\nclass(result)\n\n[1] \"list\"\n\n\nHow many things does it have?\n\nlength(result)\n\n[1] 3\n\n\nWhat are those things?\n\nprint(result)\n\n[[1]]\n[1] \"Your name is Alan and your name has 4 characters\"\n\n[[2]]\n[1] \"Your name is Beryl and your name has 5 characters\"\n\n[[3]]\n[1] \"Your name is Carlos and your name has 6 characters\"\n\n\nThe function used doesn’t have to be constructed on the fly (which we call an anonymous or unnamed function), but could be any function listed only by name. This makes it look a bit weird to the untrained eye. But as long as the function accepts one argument, R will deliver that argument for you. Below we used a previously defined function, nchar(), as an example. Note that we switch to iterating over the elements rather than the names of the elements.\n\nresult = lapply(x, nchar)\nprint(result)\n\n$A\n[1] 4\n\n$B\n[1] 5\n\n$C\n[1] 6\n\n\nThat seems to work, but how did the result get the names A, B and C while it didn’t before? Result naming happens because R tries hard to be useful. When you iterate over a named listing, R will transfer those names to the resulting output (very helpful!)\nSo, lapply produces a list. What about sapply()?\n\n\nsapply()\nsapply() operates just like lapply() except it tries very hard to simplify the output into a vector or matrix if possible. If R can’t figure out how to simplify the output, then it will likely return a list.\n\nresult = sapply(x, nchar)\n\nLet’s query this output the same way.\nSo what is in result?\n\nclass(result)\n\n[1] \"integer\"\n\n\nHow many things does it have?\n\nlength(result)\n\n[1] 3\n\n\nWhat are those things?\n\nprint(result)\n\nA B C \n4 5 6 \n\n\nOh, interesting, unlike lapply which produced a named list, sapply produced a named vector - thus “simplified”!\nYou can suppress the the simplification to make sapply just like lapply.\n\nresult = sapply(x, nchar, simplify = FALSE) |&gt;\n  print()\n\n$A\n[1] 4\n\n$B\n[1] 5\n\n$C\n[1] 6\n\n\nSo, sapply can produce a simple vector, but it can also produce a list. What about producing a matrix? And do you even want that? (Answer: sometimes!) A matrix is produced when the function produces a vector of more than one element. Below we define an anonymous function that returns a two element vector (name and value). Note that we are now iterating over the names of x rather than the elements of x.\n\nresult = sapply(names(x), \n                function(name){\n                  return(c(name, x[[name]]))\n                })\n\nLet’s query the output…\n\nstr(result)\n\n chr [1:2, 1:3] \"A\" \"Alan\" \"B\" \"Beryl\" \"C\" \"Carlos\"\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : chr [1:3] \"A\" \"B\" \"C\"\n\n\nWell, there we go, a 2-row, 3-column matrix.\n\nprint(result)\n\n     A      B       C       \n[1,] \"A\"    \"B\"     \"C\"     \n[2,] \"Alan\" \"Beryl\" \"Carlos\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are like most mortals you may be disappointed that the matrix looks sideways. It feels like it should be a column of names (A, B and C) followed by a column of items (Alan, Beryl and Carlos) rather than a row of each. You can switch things to make it look righter using the matrix transpose function t().\n\nt(result)\n\n  [,1] [,2]    \nA \"A\"  \"Alan\"  \nB \"B\"  \"Beryl\" \nC \"C\"  \"Carlos\"\n\n\nThat feels better somehow.",
    "crumbs": [
      "Iterations"
    ]
  },
  {
    "objectID": "iterations.html#groups-in-a-table",
    "href": "iterations.html#groups-in-a-table",
    "title": "Iterations",
    "section": "Groups in a table",
    "text": "Groups in a table\nIt is very common to have a flat table (data.frame) where rows are grouped, not in contiguous rows perhaps, but by a common value in a particular column. In fact, you may have the need to have multiple groupings - nested groups, where we first group by “this” and then within each of those groups we group by “that”. There’s no limited on how many nested groups you might envision in a table. The dplyr package and friends provide easy utilities for iterating over these groups. In this case, the process is loosely described as mapping a portion of a table (a group) to a function. There are a number of these utilities, but we’ll focus on group_map().\n\nAn example table\nWe have created a function that produces a table in the E pluribus unum tutorial. The table is synthetic data about a study on fictitious guppies.\n\nsource(\"setup.R\")\n\nhere() starts at /Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R\n\nx = read_guppy() |&gt;\n  print()\n\n# A tibble: 105 × 11\n   site_id       x        y time                researcher shade gps_codes    id\n   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         1\n 2 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         2\n 3 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         3\n 4 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         4\n 5 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         5\n 6 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         6\n 7 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         7\n 8 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         8\n 9 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         9\n10 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q        10\n# ℹ 95 more rows\n# ℹ 3 more variables: treatment &lt;chr&gt;, count &lt;dbl&gt;, dose &lt;dbl&gt;\n\n\n\n\nSet up the groups\nLet’s do something very simple; “for each treatment-shade group, let’s craft a table of the minimum and maximum doses, as well as the mean count.” Note that we use the same iterative language we used above, “for each thing do this”, where in this case “thing” means treatment-shade group.\nFirst, let’s see how many treatment groups we should expect.\n\nngroups = dplyr::count(x, treatment, shade) |&gt;\n  print()\n\n# A tibble: 19 × 3\n   treatment shade     n\n   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n 1 A            20     3\n 2 A            30     3\n 3 A            40     3\n 4 A            50     9\n 5 B            20     1\n 6 B            30     7\n 7 B            40     5\n 8 B            50    12\n 9 C            20     4\n10 C            30     3\n11 C            40     6\n12 C            50    11\n13 D            30     3\n14 D            40     6\n15 D            50    10\n16 E            20     2\n17 E            30     2\n18 E            40     5\n19 E            50    10\n\n\nOK, there are 19 treatment-shade groups so we should expect our summary table to have 19 rows (one for each treatment-shade group.) This is good info to have to help check our work.\nNext we assign to the table the identity of the grouping variable - that is, which column contains the treatment-shade identifiers\n\nx = dplyr::group_by(x, treatment, shade) |&gt;\n  print()\n\n# A tibble: 105 × 11\n# Groups:   treatment, shade [19]\n   site_id       x        y time                researcher shade gps_codes    id\n   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         1\n 2 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         2\n 3 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         3\n 4 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         4\n 5 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         5\n 6 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         6\n 7 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         7\n 8 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         8\n 9 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q         9\n10 site_01 452032. 4857765. 2020-05-16 07:26:25 JPO           30 c-q-q        10\n# ℹ 95 more rows\n# ℹ 3 more variables: treatment &lt;chr&gt;, count &lt;dbl&gt;, dose &lt;dbl&gt;\n\n\nThe only change here is that we see a notation, in the header, about the groupings. We can access information about the groupings, including the names of the grouping variables…\n\ndplyr::groups(x)\n\n[[1]]\ntreatment\n\n[[2]]\nshade\n\n\n… a table of the keys (the values of each group)…\n\ndplyr::group_keys(x)\n\n# A tibble: 19 × 2\n   treatment shade\n   &lt;chr&gt;     &lt;dbl&gt;\n 1 A            20\n 2 A            30\n 3 A            40\n 4 A            50\n 5 B            20\n 6 B            30\n 7 B            40\n 8 B            50\n 9 C            20\n10 C            30\n11 C            40\n12 C            50\n13 D            30\n14 D            40\n15 D            50\n16 E            20\n17 E            30\n18 E            40\n19 E            50\n\n\n… or even a listing of the row numbers for each group…\n\ndplyr::group_data(x)\n\n# A tibble: 19 × 3\n   treatment shade       .rows\n   &lt;chr&gt;     &lt;dbl&gt; &lt;list&lt;int&gt;&gt;\n 1 A            20         [3]\n 2 A            30         [3]\n 3 A            40         [3]\n 4 A            50         [9]\n 5 B            20         [1]\n 6 B            30         [7]\n 7 B            40         [5]\n 8 B            50        [12]\n 9 C            20         [4]\n10 C            30         [3]\n11 C            40         [6]\n12 C            50        [11]\n13 D            30         [3]\n14 D            40         [6]\n15 D            50        [10]\n16 E            20         [2]\n17 E            30         [2]\n18 E            40         [5]\n19 E            50        [10]\n\n\nThis is perfect! Just what we might need to iterate over each grouping. The first group (treatment = A, shade = 20) has three records which we find at rows 73, 74 and 75. Now we could iterate over each row of the group_data(x) output, fishing out the rows for each and then making our computations. But…\nThe dplyr provides a set of tools that perform much of what we have seen with lapply() and sapply() - running an iterator, applying a function and returning something. These functions are group_map(), group_walk() and group_modify(). We’ll focus only upon group_map(), but do check out the others. Also, keep in mind there are hundreds of examples and tutorials on the web that you can follow.\nJust like with lapply() and sapply(), we need a function to operate upon each group. Unlike lapply() and sapply(), the function we use (or create) must accept two positional arguments. The first, which we call tbl (short for table), contains the data for the group while the second, which we call key contains a tiny table of the key for that group. In our example, the key for each iteration would be one row of the output of group_keys(x) that you see above.\n\n\n\n\n\n\nNote\n\n\n\nYou can call those two arguments whatever you like. We adopt tbl and key only as a convention that we like. You can devise your own convention, or use different argument names every time (as long as your head doesn’t explode.)\n\n\nHere’s a reminder of our goal: “for each treatment-shade group, let’s craft a table of the minimum and maximum doses, as well as the mean count.” So, our function needs to compute the min and max doses, as well as the mean count. Now key will be a little table with treatment and shade, we could simply mutate that, adding columns for min_dose, max_dose and mean_count. Of course, the actual data for dose and count will be in the first argument, tbl.\n\nsummarize_one_group = function(tbl, key){\n  key = key |&gt;\n    dplyr::mutate(min_dose = min(tbl$dose),\n                  max_dose = max(tbl$dose),\n                  mean_count = mean(tbl$count))\n  return(key)\n}\n\nOK, so how do we use the function? It’s easy, much as you did for, say lapply(), you provide the thing to iterate over and the function to apply at each iteration.\n\nresult = dplyr::group_map(x, summarize_one_group)\n\nBut what is in the result? (Hopefully 19!)\n\nlength(result) \n\n[1] 19\n\n\nLet’s look at just the first three items returned.\n\nresult[seq_len(3)]\n\n[[1]]\n# A tibble: 1 × 5\n  treatment shade min_dose max_dose mean_count\n  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1 A            20        0      0.8       56.7\n\n[[2]]\n# A tibble: 1 × 5\n  treatment shade min_dose max_dose mean_count\n  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1 A            30      0.4      0.9       49.7\n\n[[3]]\n# A tibble: 1 × 5\n  treatment shade min_dose max_dose mean_count\n  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1 A            40        0      0.3         52\n\n\nOK - so we got back 19 tables, well those are easy to bind into one table.\n\nresult = dplyr::bind_rows(result) |&gt;\n  print()\n\n# A tibble: 19 × 5\n   treatment shade min_dose max_dose mean_count\n   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 A            20      0        0.8       56.7\n 2 A            30      0.4      0.9       49.7\n 3 A            40      0        0.3       52  \n 4 A            50      0        1         49.9\n 5 B            20      1        1         31  \n 6 B            30      0        1         57.1\n 7 B            40      0        0.8       48.6\n 8 B            50      0        1         45.9\n 9 C            20      0        0.9       46  \n10 C            30      0.7      1         40.3\n11 C            40      0.2      1         40.8\n12 C            50      0.2      1         47.7\n13 D            30      0.5      0.7       42.3\n14 D            40      0.1      0.9       57.7\n15 D            50      0.1      1         49.2\n16 E            20      0.1      0.7       51.5\n17 E            30      0.8      0.8       54.5\n18 E            40      0.7      0.9       63.4\n19 E            50      0        1         41.6\n\n\nWell, that was easy. It’s not unusual to compress these steps into one convenient workflow.\n\nresult = dplyr::group_by(x, treatment, shade) |&gt;\n  dplyr::group_map(summarize_one_group) |&gt;\n  dplyr::bind_rows() |&gt;\n  print()\n\n# A tibble: 19 × 5\n   treatment shade min_dose max_dose mean_count\n   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1 A            20      0        0.8       56.7\n 2 A            30      0.4      0.9       49.7\n 3 A            40      0        0.3       52  \n 4 A            50      0        1         49.9\n 5 B            20      1        1         31  \n 6 B            30      0        1         57.1\n 7 B            40      0        0.8       48.6\n 8 B            50      0        1         45.9\n 9 C            20      0        0.9       46  \n10 C            30      0.7      1         40.3\n11 C            40      0.2      1         40.8\n12 C            50      0.2      1         47.7\n13 D            30      0.5      0.7       42.3\n14 D            40      0.1      0.9       57.7\n15 D            50      0.1      1         49.2\n16 E            20      0.1      0.7       51.5\n17 E            30      0.8      0.8       54.5\n18 E            40      0.7      0.9       63.4\n19 E            50      0        1         41.6",
    "crumbs": [
      "Iterations"
    ]
  },
  {
    "objectID": "files-header-table.html",
    "href": "files-header-table.html",
    "title": "Tricky files",
    "section": "",
    "text": "Some files are easy to read like CSV or Excel or TEXT files. They provide clean tabular data, often with meaningful column names, and we can generally rely upon existing software to read them for us.\nBut not all files. Sometimes you will encounter files that look easy to read but have a funny hitch like a header section before the table, or a header section followed by binary table (we are looking at you, flow cytometrists!)\nHere we have a file that is simply a small header section followed by a plain old CSV table with 18 records. Here are the first few lines followed by the last 2.\n## Guppy studies\nSITE: site_01\nCOORDS (x y crs): 452032.1 4857765.1 EPSG:26919\nTIME: 2020-05-16T07:26:25 UTC\n## data\nid,treatment,count,dose\n1,C,32,0.7\n2,B,71,0.5\n3,D,54,0.6\n4,C,57,0.7\n    .\n    .\n    .\n17,D,37,0.5\n18,E,60,0.8\nNow we have table readers galore to chose among including read.csv and reader::read_csv. Each includes a skip argument to skip over the header which we can use to read the table alone.\n\nRead the table\n\nsource(\"setup.R\")\n\nhere() starts at /Users/ben/Library/CloudStorage/Dropbox/code/projects/TCOF-R\n\nx = readr::read_csv(\"data/guppy/site_01/site_01.gup\",\n                    show_col_types = FALSE,\n                    skip = 5,\n                    col_names = TRUE) |&gt;\n  dplyr::glimpse()\n\nRows: 18\nColumns: 4\n$ id        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18\n$ treatment &lt;chr&gt; \"C\", \"B\", \"D\", \"C\", \"C\", \"A\", \"B\", \"B\", \"A\", \"B\", \"B\", \"A\", …\n$ count     &lt;dbl&gt; 32, 71, 54, 57, 32, 55, 66, 61, 60, 33, 67, 34, 42, 60, 49, …\n$ dose      &lt;dbl&gt; 0.7, 0.5, 0.6, 0.7, 1.0, 0.4, 0.0, 0.0, 0.6, 0.4, 0.0, 0.9, …\n\n\nSo that’s pretty easy, but what happens if it is important to attach some of the header info to the table we read? How do we read that and attach it as a attribute to the table?\n\n\nRead the header\nWe could follow a different path by reading the first 4 lines as a character (string) vector and parsing what we need for the text. Then we could use the above to read the remainder of the file as a table.\n\nss = readLines(\"data/guppy/site_01/site_01.gup\", n = 4) |&gt;\n  stringr::str_split(stringr::fixed(\": \"), n = 2)\nss = ss[-1]    # we don't need the first line\nss\n\n[[1]]\n[1] \"SITE\"    \"site_01\"\n\n[[2]]\n[1] \"COORDS (x y crs)\"              \"452032.1 4857765.1 EPSG:26919\"\n\n[[3]]\n[1] \"TIME\"                    \"2020-05-16T07:26:25 UTC\"\n\n\nstr_split() always produces a list with one element for each line of text.\n\n\nParse the header\nNow we have a list with one element per line of text, where each element has 2 elements itself: the string before “:” and the string after “:” . Extracting the site is easy,\n\nsite = ss[[1]][2]  # the second element of the first element\nsite\n\n[1] \"site_01\"\n\n\nand the time should be a straight forward conversion to a date-time class.\n\ntime = ss[[3]][2] |&gt;  # the second element of the third element\n  as.POSIXct(format = \"%Y-%m-%dT%H:%M:%S UTC\", tz = \"UTC\")\ntime\n\n[1] \"2020-05-16 07:26:25 UTC\"\n\n\nBut what of the second line? It has three bits of info: two numerics (x and y) and one string (crs). Well, first let’s extract them.\n\n                         # the second element of the second element\nxyc = stringr::str_split(ss[[2]][2], stringr::fixed(\" \"), n = 3)\nxyc\n\n[[1]]\n[1] \"452032.1\"   \"4857765.1\"  \"EPSG:26919\"\n\n\nKeep in mind the str_split() returns a list with one element per line of input. So this should be easy to make a list we can subsequently attach to the table as an attribute.\n\nxcoord = xyc[[1]][1] |&gt; as.numeric()  # first element of first element\nycoord = xyc[[1]][2] |&gt; as.numeric()  # second element of first element\ncrs = xyc[[1]][3]                     # third element of first element\n\n\n\nAdd as an attribute\nYou can have anything as an attribute to an object using the attr() function. Attributes are small bits of metadata associated with the object to which it is attached. Whether it is a good idea add an attribute is often worth debating especially if the attribute is large or you need ready access to it. But in the case it is a small bit of info and may not be useful in an immediate sense. Below we attach a “metadata” attribute to our table, x.\n\nmy_atts = list(site_id = site,\n               time = time,\n               x = xcoord,\n               y = ycoord,\n               crs = crs)\n\nattr(x, \"metadata\") = my_atts\n\nYou can get all of the attributes (prepare yourself - it can be a lot!) using attributes(). Keep in mind that other steps may have added attributes to your table, too.\n\nattributes(x)\n\n$row.names\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18\n\n$names\n[1] \"id\"        \"treatment\" \"count\"     \"dose\"     \n\n$spec\ncols(\n  id = col_double(),\n  treatment = col_character(),\n  count = col_double(),\n  dose = col_double()\n)\n\n$problems\n&lt;pointer: 0x7fa59c7b76a0&gt;\n\n$class\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n$metadata\n$metadata$site_id\n[1] \"site_01\"\n\n$metadata$time\n[1] \"2020-05-16 07:26:25 UTC\"\n\n$metadata$x\n[1] 452032.1\n\n$metadata$y\n[1] 4857765\n\n$metadata$crs\n[1] \"EPSG:26919\"\n\n\nBut, there at the end, you can see your attributes in ‘metadata’. We can get those back if needed.\n\nmy_atts = attr(x, \"metadata\")\nmy_atts\n\n$site_id\n[1] \"site_01\"\n\n$time\n[1] \"2020-05-16 07:26:25 UTC\"\n\n$x\n[1] 452032.1\n\n$y\n[1] 4857765\n\n$crs\n[1] \"EPSG:26919\"\n\n\n\n\nIn another context\nIn the E pluribus unum tutorial we will read these files in a slightly different way, but we use the same approach - read the header as a block of text and then read the remainder as a table. What we do with the header info in that other context is different than here. In that other context we only add the crs as an attribute. site_id, time, x and y are not added as attributes, but instead are added as new variables (columns) in the table.\n\nx = x |&gt;\n  dplyr::mutate(\n    site_id = site,\n    time = time,\n    x = xcoord,\n    y = ycoord, \n    .before = 1) |&gt;\n  dplyr::glimpse()\n\nRows: 18\nColumns: 8\n$ site_id   &lt;chr&gt; \"site_01\", \"site_01\", \"site_01\", \"site_01\", \"site_01\", \"site…\n$ time      &lt;dttm&gt; 2020-05-16 07:26:25, 2020-05-16 07:26:25, 2020-05-16 07:26:…\n$ x         &lt;dbl&gt; 452032.1, 452032.1, 452032.1, 452032.1, 452032.1, 452032.1, …\n$ y         &lt;dbl&gt; 4857765, 4857765, 4857765, 4857765, 4857765, 4857765, 485776…\n$ id        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18\n$ treatment &lt;chr&gt; \"C\", \"B\", \"D\", \"C\", \"C\", \"A\", \"B\", \"B\", \"A\", \"B\", \"B\", \"A\", …\n$ count     &lt;dbl&gt; 32, 71, 54, 57, 32, 55, 66, 61, 60, 33, 67, 34, 42, 60, 49, …\n$ dose      &lt;dbl&gt; 0.7, 0.5, 0.6, 0.7, 1.0, 0.4, 0.0, 0.0, 0.6, 0.4, 0.0, 0.9, …\n\n\nIt’s just a different approach and may seem, at this time, like a silly waste of data space since every row has the same values for site_id, time, x and y. But in that other context it is a gold mine.",
    "crumbs": [
      "Files with bad headers"
    ]
  }
]